{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN for gmm_diag.stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pystan\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "import itertools\n",
    "import datetime\n",
    "import os, sys, subprocess, os.path, shutil\n",
    "FNULL = open(os.devnull, 'w')\n",
    "def execute(command):    \n",
    "    popen = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)\n",
    "    lines_iterator = iter(popen.stdout.readline, b\"\")\n",
    "    for line in lines_iterator:\n",
    "        print(line), # yield line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " method = sample (Default)\n",
      "   sample\n",
      "     num_samples = 1000 (Default)\n",
      "     num_warmup = 1000 (Default)\n",
      "     save_warmup = 1\n",
      "     thin = 1 (Default)\n",
      "     adapt\n",
      "       engaged = 1 (Default)\n",
      "       gamma = 0.050000000000000003 (Default)\n",
      "       delta = 0.80000000000000004 (Default)\n",
      "       kappa = 0.75 (Default)\n",
      "       t0 = 10 (Default)\n",
      "       init_buffer = 75 (Default)\n",
      "       term_buffer = 50 (Default)\n",
      "       window = 25 (Default)\n",
      "     algorithm = hmc (Default)\n",
      "       hmc\n",
      "         engine = nuts (Default)\n",
      "           nuts\n",
      "             max_depth = 10 (Default)\n",
      "         metric = diag_e (Default)\n",
      "         stepsize = 1 (Default)\n",
      "         stepsize_jitter = 0 (Default)\n",
      " id = 0 (Default)\n",
      " data\n",
      "   file = training.data.R\n",
      " init = 2 (Default)\n",
      " random\n",
      "   seed = 1\n",
      " output\n",
      "   file = output_nuts.csv\n",
      "   diagnostic_file =  (Default)\n",
      "   refresh = 100 (Default)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0.002049 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 20.49 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "\n",
      "Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Exception thrown at line 36: stan::math::normal_log: Scale parameter[2] is 0, but must be > 0!\n",
      "If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "\n",
      "Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Exception thrown at line 36: stan::math::normal_log: Scale parameter[2] is 0, but must be > 0!\n",
      "If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "Iteration:  100 / 2000 [  5%]  (Warmup)\n",
      "Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Iteration:  300 / 2000 [ 15%]  (Warmup)\n",
      "Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Iteration:  500 / 2000 [ 25%]  (Warmup)\n",
      "Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Iteration:  700 / 2000 [ 35%]  (Warmup)\n",
      "Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Iteration:  900 / 2000 [ 45%]  (Warmup)\n",
      "Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Iteration: 1100 / 2000 [ 55%]  (Sampling)\n",
      "Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Iteration: 1300 / 2000 [ 65%]  (Sampling)\n",
      "Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Iteration: 1500 / 2000 [ 75%]  (Sampling)\n",
      "Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Iteration: 1700 / 2000 [ 85%]  (Sampling)\n",
      "Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Iteration: 1900 / 2000 [ 95%]  (Sampling)\n",
      "Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "\n",
      "#  Elapsed Time: 34.5706 seconds (Warm-up)\n",
      "#                13.9934 seconds (Sampling)\n",
      "#                48.564 seconds (Total)\n",
      "\n",
      " method = variational\n",
      "   variational\n",
      "     algorithm = meanfield (Default)\n",
      "       meanfield\n",
      "     iter = 10000 (Default)\n",
      "     grad_samples = 1 (Default)\n",
      "     elbo_samples = 100 (Default)\n",
      "     eta_adagrad = 0.5\n",
      "     tol_rel_obj = 0.014999999999999999\n",
      "     eval_elbo = 10\n",
      "     output_samples = 1000 (Default)\n",
      " id = 0 (Default)\n",
      " data\n",
      "   file = training.data.R\n",
      " init = 2 (Default)\n",
      " random\n",
      "   seed = 1\n",
      " output\n",
      "   file = output_mf.csv\n",
      "   diagnostic_file = elbo_mf.csv\n",
      "   refresh = 100 (Default)\n",
      "\n",
      "\n",
      "This is Automatic Differentiation Variational Inference.\n",
      "\n",
      "(EXPERIMENTAL ALGORITHM: expect frequent updates to the procedure.)\n",
      "\n",
      "Gradient evaluation took 0.001956 seconds\n",
      "1000 iterations under these settings should take 1.956 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "  iter       ELBO   delta_ELBO_mean   delta_ELBO_med   notes \n",
      "     0     -1e+05             1.000            1.000\n",
      "    10   -35382.2             1.696            2.392\n",
      "    20   -18471.9             1.436            1.000\n",
      "    30   -18265.1             1.080            1.000\n",
      "    40   -17880.4             0.868            0.915\n",
      "    50   -17680.1             0.725            0.915\n",
      "    60   -18283.9             0.626            0.033\n",
      "    70   -17822.9             0.551            0.033\n",
      "    80   -18923.0             0.496            0.033\n",
      "    90   -17849.7             0.453            0.058\n",
      "   100   -17604.4             0.413            0.033\n",
      "   110   -17796.7             0.379            0.033\n",
      "   120   -18245.4             0.352            0.026\n",
      "   130   -17744.4             0.329            0.028\n",
      "   140   -17771.4             0.307            0.026\n",
      "   150   -17561.1             0.289            0.026\n",
      "   160   -17680.1             0.272            0.025\n",
      "   170   -17784.5             0.257            0.025\n",
      "   180   -17802.0             0.244            0.022\n",
      "   190   -17833.4             0.232            0.022\n",
      "   200   -17856.4             0.221            0.014   MEDIAN ELBO CONVERGED\n"
     ]
    }
   ],
   "source": [
    "# Run NUTS and ADVI using these commands\n",
    "\n",
    "nuts_execution = \"./gmm_diag sample save_warmup=1 data file=training.data.R \"\n",
    "nuts_execution += \"output file=output_nuts.csv random seed=1\"\n",
    "\n",
    "advi_execution = \"./gmm_diag variational eta_adagrad=0.5 eval_elbo=10 tol_rel_obj=0.015 \"\n",
    "advi_execution += \"data file=training.data.R \"\n",
    "advi_execution += \"output file=output_mf.csv diagnostic_file=elbo_mf.csv random seed=1\"\n",
    "\n",
    "subprocess.call('rm -rf *.csv', shell=True, stdout=FNULL)\n",
    "execute(nuts_execution)\n",
    "execute(advi_execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define log_pred Stan program\n",
    "execution_string = \"./gmm_diag_logpred sample algorithm=fixed_param num_samples=1 \"\n",
    "execution_string += \"data file=logpred.data.R output file=output_logpred.csv\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make copies of timing CSV files because the log_pred calculations will overwrite them.\n",
    "shutil.copy('warmup_timing.csv', 'warmup_timing_ORIG.csv')\n",
    "shutil.copy('sample_timing.csv', 'sample_timing_ORIG.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Form the basic structure of the held-out logpredictive \"dataset\"\n",
    "testing = pystan.misc.read_rdump('training.data.R')\n",
    "\n",
    "datadict = {}\n",
    "\n",
    "block_size = 25 # this has to match `num_intermediate_samples` in `advi.hpp`\n",
    "datadict['S']         = block_size\n",
    "datadict['K']         = testing['K']\n",
    "datadict['D']         = testing['D']\n",
    "datadict['N']         = testing['N']\n",
    "datadict['y_heldout'] = testing['y'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing iterations 0 to 25 \tave_log_pred:      -8.9 at 3.1496\n",
      "Processing iterations 25 to 50 \tave_log_pred:      -8.4 at 11.1335\n",
      "Processing iterations 50 to 75 \tave_log_pred:      -8.4 at 16.3878\n",
      "Processing iterations 75 to 100 \tave_log_pred:      -8.4 at 22.6683\n",
      "Processing iterations 100 to 125 \tave_log_pred:      -8.4 at 23.0548\n",
      "Processing iterations 125 to 150 \tave_log_pred:      -8.4 at 23.4815\n",
      "Processing iterations 150 to 175 \tave_log_pred:      -8.4 at 23.8751\n",
      "Processing iterations 175 to 200 \tave_log_pred:      -8.4 at 24.2119\n",
      "Processing iterations 200 to 225 \tave_log_pred:      -8.4 at 24.5266\n",
      "Processing iterations 225 to 250 \tave_log_pred:      -8.4 at 24.8849\n",
      "Processing iterations 250 to 275 \tave_log_pred:      -8.4 at 25.3881\n",
      "Processing iterations 275 to 300 \tave_log_pred:      -8.4 at 25.7621\n",
      "Processing iterations 300 to 325 \tave_log_pred:      -8.4 at 26.1455\n",
      "Processing iterations 325 to 350 \tave_log_pred:      -8.4 at 26.4604\n",
      "Processing iterations 350 to 375 \tave_log_pred:      -8.4 at 26.7873\n",
      "Processing iterations 375 to 400 \tave_log_pred:      -8.4 at 27.0644\n",
      "Processing iterations 400 to 425 \tave_log_pred:      -8.4 at 27.3415\n",
      "Processing iterations 425 to 450 \tave_log_pred:      -8.4 at 27.6707\n",
      "Processing iterations 450 to 475 \tave_log_pred:      -8.4 at 28.1391\n",
      "Processing iterations 475 to 500 \tave_log_pred:      -8.4 at 28.5861\n",
      "Processing iterations 500 to 525 \tave_log_pred:      -8.4 at 28.9176\n",
      "Processing iterations 525 to 550 \tave_log_pred:      -8.4 at 29.2417\n",
      "Processing iterations 550 to 575 \tave_log_pred:      -8.4 at 29.558\n",
      "Processing iterations 575 to 600 \tave_log_pred:      -8.4 at 29.8314\n",
      "Processing iterations 600 to 625 \tave_log_pred:      -8.4 at 30.0858\n",
      "Processing iterations 625 to 650 \tave_log_pred:      -8.4 at 30.3646\n",
      "Processing iterations 650 to 675 \tave_log_pred:      -8.4 at 30.653\n",
      "Processing iterations 675 to 700 \tave_log_pred:      -8.4 at 30.9264\n",
      "Processing iterations 700 to 725 \tave_log_pred:      -8.4 at 31.228\n",
      "Processing iterations 725 to 750 \tave_log_pred:      -8.4 at 31.529\n",
      "Processing iterations 750 to 775 \tave_log_pred:      -8.4 at 31.8204\n",
      "Processing iterations 775 to 800 \tave_log_pred:      -8.4 at 32.14\n",
      "Processing iterations 800 to 825 \tave_log_pred:      -8.4 at 32.4212\n",
      "Processing iterations 825 to 850 \tave_log_pred:      -8.4 at 32.6835\n",
      "Processing iterations 850 to 875 \tave_log_pred:      -8.4 at 32.9474\n",
      "Processing iterations 875 to 900 \tave_log_pred:      -8.4 at 33.2398\n",
      "Processing iterations 900 to 925 \tave_log_pred:      -8.4 at 33.5093\n",
      "Processing iterations 925 to 950 \tave_log_pred:      -8.4 at 33.7897\n",
      "Processing iterations 950 to 975 \tave_log_pred:      -8.4 at 34.2364\n",
      "Processing iterations 975 to 1000 \tave_log_pred:      -8.4 at 34.5704\n",
      "Processing iterations 1000 to 1025 \tave_log_pred:      -8.4 at 34.913388\n",
      "Processing iterations 1025 to 1050 \tave_log_pred:      -8.4 at 35.237099\n",
      "Processing iterations 1050 to 1075 \tave_log_pred:      -8.4 at 35.562585\n",
      "Processing iterations 1075 to 1100 \tave_log_pred:      -8.4 at 35.91468\n",
      "Processing iterations 1100 to 1125 \tave_log_pred:      -8.4 at 36.24439\n",
      "Processing iterations 1125 to 1150 \tave_log_pred:      -8.4 at 36.59463\n",
      "Processing iterations 1150 to 1175 \tave_log_pred:      -8.4 at 36.95293\n",
      "Processing iterations 1175 to 1200 \tave_log_pred:      -8.4 at 37.30219\n",
      "Processing iterations 1200 to 1225 \tave_log_pred:      -8.4 at 37.66923\n",
      "Processing iterations 1225 to 1250 \tave_log_pred:      -8.4 at 38.01213\n",
      "Processing iterations 1250 to 1275 \tave_log_pred:      -8.4 at 38.35611\n",
      "Processing iterations 1275 to 1300 \tave_log_pred:      -8.4 at 38.66539\n",
      "Processing iterations 1300 to 1325 \tave_log_pred:      -8.4 at 39.00224\n",
      "Processing iterations 1325 to 1350 \tave_log_pred:      -8.4 at 39.33856\n",
      "Processing iterations 1350 to 1375 \tave_log_pred:      -8.4 at 39.70418\n",
      "Processing iterations 1375 to 1400 \tave_log_pred:      -8.4 at 40.0609\n",
      "Processing iterations 1400 to 1425 \tave_log_pred:      -8.4 at 40.4141\n",
      "Processing iterations 1425 to 1450 \tave_log_pred:      -8.4 at 40.80013\n",
      "Processing iterations 1450 to 1475 \tave_log_pred:      -8.4 at 41.18337\n",
      "Processing iterations 1475 to 1500 \tave_log_pred:      -8.4 at 41.5075\n",
      "Processing iterations 1500 to 1525 \tave_log_pred:      -8.4 at 41.87221\n",
      "Processing iterations 1525 to 1550 \tave_log_pred:      -8.4 at 42.22558\n",
      "Processing iterations 1550 to 1575 \tave_log_pred:      -8.4 at 42.56718\n",
      "Processing iterations 1575 to 1600 \tave_log_pred:      -8.4 at 42.93962\n",
      "Processing iterations 1600 to 1625 \tave_log_pred:      -8.4 at 43.32306\n",
      "Processing iterations 1625 to 1650 \tave_log_pred:      -8.4 at 43.6607\n",
      "Processing iterations 1650 to 1675 \tave_log_pred:      -8.4 at 44.04701\n",
      "Processing iterations 1675 to 1700 \tave_log_pred:      -8.4 at 44.38702\n",
      "Processing iterations 1700 to 1725 \tave_log_pred:      -8.4 at 44.7263\n",
      "Processing iterations 1725 to 1750 \tave_log_pred:      -8.4 at 45.0733\n",
      "Processing iterations 1750 to 1775 \tave_log_pred:      -8.4 at 45.4279\n",
      "Processing iterations 1775 to 1800 \tave_log_pred:      -8.4 at 45.7709\n",
      "Processing iterations 1800 to 1825 \tave_log_pred:      -8.4 at 46.1499\n",
      "Processing iterations 1825 to 1850 \tave_log_pred:      -8.4 at 46.513\n",
      "Processing iterations 1850 to 1875 \tave_log_pred:      -8.4 at 46.89\n",
      "Processing iterations 1875 to 1900 \tave_log_pred:      -8.4 at 47.2222\n",
      "Processing iterations 1900 to 1925 \tave_log_pred:      -8.4 at 47.5603\n",
      "Processing iterations 1925 to 1950 \tave_log_pred:      -8.4 at 47.8913\n",
      "Processing iterations 1950 to 1975 \tave_log_pred:      -8.4 at 48.2423\n",
      "Processing iterations 1975 to 2000 \tave_log_pred:      -8.4 at 48.5637\n"
     ]
    }
   ],
   "source": [
    "## NUTS \n",
    "\n",
    "# Get timing results\n",
    "warmup_timing = np.genfromtxt('warmup_timing_ORIG.csv', delimiter=',')[:,1]\n",
    "sample_timing = np.genfromtxt('sample_timing_ORIG.csv', delimiter=',')[:,1]\n",
    "sample_timing = sample_timing + warmup_timing[-1] # stan resets the timer\n",
    "full_timing_nuts = np.concatenate([warmup_timing, sample_timing])\n",
    "\n",
    "# The first 6 columns are useless for us\n",
    "samples = np.genfromtxt('output_nuts.csv', delimiter=',')[1:,6:]\n",
    "N_test = samples.shape[0]\n",
    "K = testing['K']\n",
    "D = testing['D']\n",
    "theta   = samples[:,0:K]\n",
    "mu      = np.reshape(samples[:, K:K+K*D], (N_test,K,D), order='F')\n",
    "sigma   = np.reshape(samples[:, K+K*D:],  (N_test,K,D), order='F')\n",
    "\n",
    "ave_log_pred_nuts = np.zeros(samples.shape[0]/block_size);\n",
    "timing_nuts = np.zeros(samples.shape[0]/block_size);\n",
    "\n",
    "for i in range(samples.shape[0]/block_size):\n",
    "    print \"Processing iterations\",\n",
    "    print i*block_size,\n",
    "    print \"to\",\n",
    "    print (i+1)*block_size,\n",
    "    \n",
    "    datadict['theta'] = theta[i*block_size:(i+1)*block_size, :]\n",
    "    datadict['mu']    = np.swapaxes(mu[i*block_size:(i+1)*block_size, :, :], 0, 1)\n",
    "    datadict['sigma'] = np.swapaxes(sigma[i*block_size:(i+1)*block_size, :, :], 0, 1)\n",
    "    # hack to make sure simplexes numerically sums up to 1\n",
    "    datadict['theta'][:,0] += 1.0 - np.sum(datadict['theta'],axis=1)\n",
    "    \n",
    "    pystan.misc.stan_rdump(datadict, 'logpred.data.R')\n",
    "    \n",
    "    subprocess.call(execution_string, shell=True, stdout=FNULL)\n",
    "    \n",
    "    ave_log_pred_nuts[i] = np.genfromtxt('output_logpred.csv', delimiter=',')[1,-1]\n",
    "    timing_nuts[i]       = full_timing_nuts[(i+1)*block_size - 1]\n",
    "    \n",
    "    print \"\\tave_log_pred: \",\n",
    "    print \"{:>8.1f}\".format(ave_log_pred_nuts[i]),\n",
    "    print \"at\",\n",
    "    print timing_nuts[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing iteration 0 \tave_log_pred:     -56.9 at 0.161838\n",
      "Processing iteration 10 \tave_log_pred:      -9.4 at 0.348537\n",
      "Processing iteration 20 \tave_log_pred:      -8.5 at 0.535009\n",
      "Processing iteration 30 \tave_log_pred:      -8.6 at 0.70565\n",
      "Processing iteration 40 \tave_log_pred:      -8.5 at 0.883079\n",
      "Processing iteration 50 \tave_log_pred:      -8.6 at 1.05464\n",
      "Processing iteration 60 \tave_log_pred:      -8.5 at 1.2282\n",
      "Processing iteration 70 \tave_log_pred:      -8.7 at 1.40945\n",
      "Processing iteration 80 \tave_log_pred:      -8.7 at 1.57933\n",
      "Processing iteration 90 \tave_log_pred:      -8.5 at 1.75375\n",
      "Processing iteration 100 \tave_log_pred:      -8.4 at 1.9283\n",
      "Processing iteration 110 \tave_log_pred:      -8.4 at 2.10983\n",
      "Processing iteration 120 \tave_log_pred:      -8.6 at 2.28801\n",
      "Processing iteration 130 \tave_log_pred:      -8.6 at 2.46359\n",
      "Processing iteration 140 \tave_log_pred:      -8.6 at 2.63687\n",
      "Processing iteration 150 \tave_log_pred:      -8.5 at 2.80877\n",
      "Processing iteration 160 \tave_log_pred:      -8.5 at 2.99057\n",
      "Processing iteration 170 \tave_log_pred:      -8.5 at 3.16487\n",
      "Processing iteration 180 \tave_log_pred:      -8.5 at 3.34477\n",
      "Processing iteration 190 \tave_log_pred:      -8.5 at 3.52993\n",
      "Processing iteration 200 \tave_log_pred:      -8.5 at 3.70771\n"
     ]
    }
   ],
   "source": [
    "## ADVI\n",
    "elbo = np.genfromtxt('elbo_mf.csv', delimiter=',')\n",
    "advi_iterations = np.array(elbo[1:,0], dtype='int')\n",
    "timing_advi = elbo[1:,1]\n",
    "\n",
    "ave_log_pred_advi = np.zeros_like(timing_advi);\n",
    "\n",
    "counter = 0;\n",
    "for i in advi_iterations:\n",
    "    print \"Processing iteration \" + str(i),\n",
    "    \n",
    "    samples = np.genfromtxt('intermediate_variational_samples_'+str(i)+'.csv', delimiter=',')[:,1:]\n",
    "\n",
    "    N_test = samples.shape[0]\n",
    "    K = testing['K']\n",
    "    D = testing['D']\n",
    "\n",
    "    theta   = samples[:,0:K]\n",
    "    mu      = np.reshape(samples[:, K:K+K*D], (N_test,K,D), order='F')\n",
    "    sigma   = np.reshape(samples[:, K+K*D:],  (N_test,K,D), order='F')\n",
    "    \n",
    "    datadict['theta'] = theta\n",
    "    datadict['mu']    = np.swapaxes(mu, 0, 1)\n",
    "    datadict['sigma'] = np.swapaxes(sigma, 0, 1)\n",
    "    # hack to make sure simplexes numerically sums up to 1\n",
    "    datadict['theta'][:,0] += 1.0 - np.sum(datadict['theta'],axis=1)\n",
    "    \n",
    "    pystan.misc.stan_rdump(datadict, 'logpred.data.R')\n",
    "\n",
    "    subprocess.call(execution_string, shell=True, stdout=FNULL)\n",
    "    \n",
    "    ave_log_pred_advi[counter] = np.genfromtxt('output_logpred.csv', delimiter=',')[1,-1]\n",
    "    \n",
    "    print \"\\tave_log_pred: \",\n",
    "    print \"{:>8.1f}\".format(ave_log_pred_advi[counter]),\n",
    "    print \"at\",\n",
    "    print timing_advi[counter] \n",
    "    \n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fi = plt.figure(figsize=(15,5))\n",
    "ax = plt.subplot()\n",
    "colors = itertools.cycle(plt.rcParams['axes.color_cycle'])\n",
    "\n",
    "this_color = next(colors)\n",
    "ax.plot(timing_nuts, ave_log_pred_nuts, lw=3, c=this_color, label='NUTS')\n",
    "\n",
    "this_color = next(colors)\n",
    "ax.plot(timing_advi, ave_log_pred_advi, lw=3, c=this_color, label='ADVI')\n",
    "\n",
    "this_color = next(colors)\n",
    "# ax.plot(timing_adsvi, ave_log_pred_adsvi, lw=3, c=this_color, label='STOCH ADVI')\n",
    "\n",
    "ax.set_xlim([0,4])\n",
    "# ax.set_xscale('log')\n",
    "\n",
    "ax.set_xlabel('Seconds')\n",
    "ax.set_ylabel('Average Log Predictive')\n",
    "ax.legend(loc=4)\n",
    "z=ax.plot()\n",
    "\n",
    "plt.savefig('gmm_plot.pdf',format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a folder to stores results\n",
    "results_directory = datetime.datetime.now().strftime(\"%Y-%m-%d_%a_%H-%M-%S\")\n",
    "if not os.path.exists(results_directory):\n",
    "    os.makedirs(results_directory)\n",
    "\n",
    "# Move all results into folder    \n",
    "source = os.listdir(\".\")\n",
    "for files in source:\n",
    "    if files.endswith(\".csv\") or files.endswith(\".pdf\"):\n",
    "        shutil.move(files,results_directory)\n",
    "        \n",
    "# Copy programs, data, and this notebook\n",
    "for files in source:\n",
    "    if files.endswith(\".stan\") or files.endswith(\".R\") or files.endswith(\".ipynb\"):\n",
    "        shutil.copy(files,results_directory)\n",
    "\n",
    "# Remove logpred.data.R to keep things clean\n",
    "os.remove(\"logpred.data.R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
